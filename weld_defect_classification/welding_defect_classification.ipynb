{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b19f86a",
      "metadata": {
        "id": "3b19f86a"
      },
      "source": [
        "# Welding Defect Image Classification \n",
        "\n",
        "Input dataset is a set of welded metal images which includes defective and non-defective ones. Classification is implemented considering three classes or target variables - cluster_porosity , cracks and no_defect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b1ad51",
      "metadata": {
        "id": "b8b1ad51"
      },
      "source": [
        "## Quick check on image distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "FE8rttsciXAE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE8rttsciXAE",
        "outputId": "0bc79fc9-4d95-4d76-d07a-17a560582a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "2\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "ls weld_images/cluster_porosity | wc -l\n",
        "ls weld_images/cracks | wc -l\n",
        "ls weld_images/no_defect | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da05f644",
      "metadata": {
        "id": "da05f644"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a6a54608",
      "metadata": {
        "id": "a6a54608"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df44131",
      "metadata": {
        "id": "9df44131"
      },
      "source": [
        "## Initialize parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "mbLE5cp5eonH",
      "metadata": {
        "id": "mbLE5cp5eonH"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "INIT_LR = 1e-3\n",
        "BS = 8\n",
        "IMAGE_DIMS = (128,800, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "290b6e8b",
      "metadata": {
        "id": "290b6e8b"
      },
      "source": [
        "## Specify classes or target variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8e6c5368",
      "metadata": {
        "id": "8e6c5368"
      },
      "outputs": [],
      "source": [
        "#directory = 'E:\\\\Welding defects classification\\\\Use Case 1-Welding Images'\n",
        "directory = 'weld_images'\n",
        "categories = ['cluster_porosity','cracks','no_defect']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8cff113",
      "metadata": {
        "id": "a8cff113"
      },
      "source": [
        "## Perform data augmentation\n",
        "\n",
        "The available dataset is very small because of which training may not produce good results. Hence, we perform data augmentation on the available dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "67829636",
      "metadata": {
        "id": "67829636"
      },
      "outputs": [],
      "source": [
        "# Function for carrying out data augmentation on the existing dataset\n",
        "\n",
        "def perform_data_aug(root_dir, category_list, aug_limit_list):\n",
        "\n",
        "        # Initialise ImageDataGenerator class.\n",
        "        datagen = ImageDataGenerator(\n",
        "                      rotation_range = 40,\n",
        "                      shear_range = 0.2,\n",
        "                      zoom_range = 0.2,\n",
        "                      horizontal_flip = True,\n",
        "                      vertical_flip = True,\n",
        "                      brightness_range = (0.5, 1.5))\n",
        "        \n",
        "        for folder,limit in zip(category_list,aug_limit_list):\n",
        "            p = os.path.join(root_dir, folder)\n",
        "            paths = list(os.walk(p))\n",
        "            \n",
        "            # Create directory for augmented images for every class\n",
        "            if not os.path.exists(folder):\n",
        "                     os.makedirs('preview_'+ folder)\n",
        "                    \n",
        "            for f in paths[0][2]:\n",
        "                \n",
        "                #Load sample image\n",
        "                full_path = os.path.join(p,f)\n",
        "                img = load_img(full_path)\n",
        "                \n",
        "                # Converting the input sample image to an array\n",
        "                x = img_to_array(img)\n",
        "                \n",
        "                # Reshaping the input image\n",
        "                x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "            # Generate and save required no. of augmented samples\n",
        "            i = 0\n",
        "            for batch in datagen.flow(x, batch_size = 1,\n",
        "                            save_to_dir ='preview_' + folder,\n",
        "                            save_prefix ='image_aug', save_format ='jpg'):\n",
        "                 i += 1\n",
        "                 if i > limit:\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "606e25cd",
      "metadata": {
        "id": "606e25cd"
      },
      "outputs": [],
      "source": [
        "# Call data augmentation function with the list of augmented images required for each class\n",
        "# This step also solves class imbalance issue which is seen in the dataset\n",
        "\n",
        "aug_limit_list = [70,80,70]\n",
        "perform_data_aug(directory, categories, aug_limit_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "aSuIsCxjEoYQ",
      "metadata": {
        "id": "aSuIsCxjEoYQ"
      },
      "outputs": [],
      "source": [
        "# Copy augmented images into respective class folders\n",
        "for c in categories:\n",
        "    src = 'preview_' + c\n",
        "    dest = os.path.join(directory, c)\n",
        "    # Fetch all files\n",
        "    for file_name in os.listdir(src):\n",
        "        # Construct full file path\n",
        "        source = os.path.join(src,file_name)\n",
        "        # Move only files\n",
        "        if os.path.isfile(source) and source.endswith('jpg'):\n",
        "            shutil.copy(source, dest)\n",
        "            #print('Moved:', file_name)\n",
        "\n",
        "    # Delete empty augment images directory\n",
        "    shutil.rmtree(src)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86ee529b",
      "metadata": {
        "id": "86ee529b"
      },
      "source": [
        "## Resize images and tag them "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "cc368678",
      "metadata": {
        "id": "cc368678"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for category in categories:\n",
        "    path = os.path.join(directory, category)\n",
        "    for img in os.listdir(path):\n",
        "        #print(img)\n",
        "        img_path = os.path.join(path, img)\n",
        "        label = category\n",
        "        arr = cv2.imread(img_path)\n",
        "        new_arr = cv2.resize(arr, (IMAGE_DIMS[1],IMAGE_DIMS[0]))\n",
        "        data.append([new_arr,label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "aafc5c93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aafc5c93",
        "outputId": "ed607482-6507-4fb7-b9e3-ed56c22080fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04abb871",
      "metadata": {
        "id": "04abb871"
      },
      "source": [
        "## Separate data into features and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5972b363",
      "metadata": {
        "id": "5972b363"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "random.shuffle(data)\n",
        "\n",
        "X, y = [],[]\n",
        "for features,labels in data:\n",
        "    X.append(features)\n",
        "    y.append(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629af814",
      "metadata": {
        "id": "629af814"
      },
      "source": [
        "## Perform normalisation on features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "757d1428",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757d1428",
        "outputId": "675ee9f0-3083-4bd9-bd67-1b7746112e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] data matrix: 580.80MB\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X, dtype=\"float\") / 255.0\n",
        "y = np.array(y)\n",
        "print(\"[INFO] data matrix: {:.2f}MB\".format(X.nbytes / (1024 * 1000.0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca7a248",
      "metadata": {
        "id": "0ca7a248"
      },
      "source": [
        "## Binarize the labels or classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "UHag4NR0XImP",
      "metadata": {
        "id": "UHag4NR0XImP"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2877e7bb",
      "metadata": {
        "id": "2877e7bb"
      },
      "source": [
        "## Split train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "01c847d6",
      "metadata": {
        "id": "01c847d6"
      },
      "outputs": [],
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7r7Ou_2KIBTm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r7Ou_2KIBTm",
        "outputId": "515bea5f-c1f3-44a3-a67c-a1bb3914d2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(193, 128, 800, 3) float64\n",
            "(49, 128, 800, 3) float64\n",
            "(193, 3) int64\n",
            "(49, 3) int64\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape, trainX.dtype)\n",
        "print(testX.shape, testX.dtype)\n",
        "print(trainY.shape, trainY.dtype)\n",
        "print(testY.shape, testY.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MbUbndlVXs5R",
      "metadata": {
        "id": "MbUbndlVXs5R"
      },
      "outputs": [],
      "source": [
        "# # Account for skew in the labeled data\n",
        "# classTotals = trainY.sum(axis=0)\n",
        "# classWeight = classTotals.max() / classTotals\n",
        "\n",
        "# category_ind = [categories.index(c) for c in categories]\n",
        "# class_weight_dic = dict(zip(category_ind, classWeight.tolist()))\n",
        "# class_weight_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "61dc5fb4",
      "metadata": {
        "id": "61dc5fb4"
      },
      "outputs": [],
      "source": [
        "# Construct image generator for data augmentation on the fly\n",
        "aug = ImageDataGenerator(rotation_range=False, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "                         horizontal_flip=True, vertical_flip=True, fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0643386e",
      "metadata": {
        "id": "0643386e"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9d905a9d",
      "metadata": {
        "id": "9d905a9d"
      },
      "outputs": [],
      "source": [
        "class SmallerVGGNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize the model along with the input shape to be\n",
        "        # \"channels last\" and the channels dimension itself\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # if we are using \"channels first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "\n",
        "        # CONV => RELU => POOL\n",
        "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "            input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        # return the constructed network architecture\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0d578f",
      "metadata": {
        "id": "df0d578f"
      },
      "source": [
        "## Initialize model with parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "2b3f9c44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b3f9c44",
        "outputId": "e605bbf5-c0f4-4ec4-a30b-e87fae3f4934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
        "                            depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61309c2",
      "metadata": {
        "id": "b61309c2"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "oBSzXjcsYbcf",
      "metadata": {
        "id": "oBSzXjcsYbcf"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44260bf7",
      "metadata": {
        "id": "44260bf7"
      },
      "source": [
        "## Create checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "_vU0KSN_YkJ5",
      "metadata": {
        "id": "_vU0KSN_YkJ5"
      },
      "outputs": [],
      "source": [
        "filepath=\"my_checkpoints/epochs:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor= 'val_accuracy' , verbose=1, save_best_only=True,\n",
        "    mode= 'max' )\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416639f1",
      "metadata": {
        "id": "416639f1"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "xJhj9i8oYwPO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJhj9i8oYwPO",
        "outputId": "e248e34d-4017-4f11-dca4-347e1dfa2971"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.8757\n",
            "Epoch 1: val_accuracy improved from -inf to 0.22449, saving model to my_checkpoints/epochs:001-val_acc:0.224.hdf5\n",
            "24/24 [==============================] - 102s 4s/step - loss: 0.9172 - accuracy: 0.8757 - val_loss: 5.5829 - val_accuracy: 0.2245\n",
            "Epoch 2/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.8000\n",
            "Epoch 2: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.6527 - accuracy: 0.8000 - val_loss: 7.2033 - val_accuracy: 0.2245\n",
            "Epoch 3/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.8216\n",
            "Epoch 3: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5877 - accuracy: 0.8216 - val_loss: 8.3854 - val_accuracy: 0.2245\n",
            "Epoch 4/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.8757\n",
            "Epoch 4: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4175 - accuracy: 0.8757 - val_loss: 4.8196 - val_accuracy: 0.2245\n",
            "Epoch 5/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.8378\n",
            "Epoch 5: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5956 - accuracy: 0.8378 - val_loss: 5.3170 - val_accuracy: 0.2245\n",
            "Epoch 6/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8595\n",
            "Epoch 6: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5381 - accuracy: 0.8595 - val_loss: 4.2405 - val_accuracy: 0.2245\n",
            "Epoch 7/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.8432\n",
            "Epoch 7: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4258 - accuracy: 0.8432 - val_loss: 4.5120 - val_accuracy: 0.2245\n",
            "Epoch 8/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8595\n",
            "Epoch 8: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5170 - accuracy: 0.8595 - val_loss: 3.4178 - val_accuracy: 0.0204\n",
            "Epoch 9/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.8649\n",
            "Epoch 9: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 88s 4s/step - loss: 0.3491 - accuracy: 0.8649 - val_loss: 4.0195 - val_accuracy: 0.2245\n",
            "Epoch 10/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8432\n",
            "Epoch 10: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5463 - accuracy: 0.8432 - val_loss: 4.3456 - val_accuracy: 0.2245\n",
            "Epoch 11/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8811\n",
            "Epoch 11: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.5167 - accuracy: 0.8811 - val_loss: 6.3206 - val_accuracy: 0.2245\n",
            "Epoch 12/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8757\n",
            "Epoch 12: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.3583 - accuracy: 0.8757 - val_loss: 4.9195 - val_accuracy: 0.2245\n",
            "Epoch 13/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8757\n",
            "Epoch 13: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 88s 4s/step - loss: 0.4448 - accuracy: 0.8757 - val_loss: 3.0132 - val_accuracy: 0.2245\n",
            "Epoch 14/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.8595\n",
            "Epoch 14: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4241 - accuracy: 0.8595 - val_loss: 4.5117 - val_accuracy: 0.2245\n",
            "Epoch 15/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.8541\n",
            "Epoch 15: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4599 - accuracy: 0.8541 - val_loss: 3.2912 - val_accuracy: 0.2245\n",
            "Epoch 16/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8811\n",
            "Epoch 16: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4289 - accuracy: 0.8811 - val_loss: 3.4996 - val_accuracy: 0.2245\n",
            "Epoch 17/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8595\n",
            "Epoch 17: val_accuracy did not improve from 0.22449\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4436 - accuracy: 0.8595 - val_loss: 3.9243 - val_accuracy: 0.2245\n",
            "Epoch 18/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.8595\n",
            "Epoch 18: val_accuracy improved from 0.22449 to 0.24490, saving model to my_checkpoints/epochs:018-val_acc:0.245.hdf5\n",
            "24/24 [==============================] - 97s 4s/step - loss: 0.5023 - accuracy: 0.8595 - val_loss: 2.2515 - val_accuracy: 0.2449\n",
            "Epoch 19/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.8324\n",
            "Epoch 19: val_accuracy improved from 0.24490 to 0.75510, saving model to my_checkpoints/epochs:019-val_acc:0.755.hdf5\n",
            "24/24 [==============================] - 98s 4s/step - loss: 0.5956 - accuracy: 0.8324 - val_loss: 0.7109 - val_accuracy: 0.7551\n",
            "Epoch 20/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8703\n",
            "Epoch 20: val_accuracy improved from 0.75510 to 0.77551, saving model to my_checkpoints/epochs:020-val_acc:0.776.hdf5\n",
            "24/24 [==============================] - 98s 4s/step - loss: 0.5012 - accuracy: 0.8703 - val_loss: 1.1908 - val_accuracy: 0.7755\n",
            "Epoch 21/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.8649\n",
            "Epoch 21: val_accuracy did not improve from 0.77551\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4959 - accuracy: 0.8649 - val_loss: 1.9662 - val_accuracy: 0.2041\n",
            "Epoch 22/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9189\n",
            "Epoch 22: val_accuracy did not improve from 0.77551\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.2771 - accuracy: 0.9189 - val_loss: 0.6937 - val_accuracy: 0.7755\n",
            "Epoch 23/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.8595\n",
            "Epoch 23: val_accuracy did not improve from 0.77551\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4203 - accuracy: 0.8595 - val_loss: 0.6908 - val_accuracy: 0.7755\n",
            "Epoch 24/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9189\n",
            "Epoch 24: val_accuracy improved from 0.77551 to 0.89796, saving model to my_checkpoints/epochs:024-val_acc:0.898.hdf5\n",
            "24/24 [==============================] - 97s 4s/step - loss: 0.3484 - accuracy: 0.9189 - val_loss: 0.2950 - val_accuracy: 0.8980\n",
            "Epoch 25/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9135\n",
            "Epoch 25: val_accuracy did not improve from 0.89796\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.3378 - accuracy: 0.9135 - val_loss: 0.9310 - val_accuracy: 0.6939\n",
            "Epoch 26/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.8865\n",
            "Epoch 26: val_accuracy improved from 0.89796 to 0.97959, saving model to my_checkpoints/epochs:026-val_acc:0.980.hdf5\n",
            "24/24 [==============================] - 97s 4s/step - loss: 0.3616 - accuracy: 0.8865 - val_loss: 0.1923 - val_accuracy: 0.9796\n",
            "Epoch 27/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.8703\n",
            "Epoch 27: val_accuracy did not improve from 0.97959\n",
            "24/24 [==============================] - 89s 4s/step - loss: 0.4308 - accuracy: 0.8703 - val_loss: 0.2096 - val_accuracy: 0.9796\n",
            "Epoch 28/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.8486\n",
            "Epoch 28: val_accuracy did not improve from 0.97959\n",
            "24/24 [==============================] - 88s 4s/step - loss: 0.6194 - accuracy: 0.8486 - val_loss: 0.2808 - val_accuracy: 0.9592\n",
            "Epoch 29/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8541\n",
            "Epoch 29: val_accuracy did not improve from 0.97959\n",
            "24/24 [==============================] - 88s 4s/step - loss: 0.5042 - accuracy: 0.8541 - val_loss: 0.4720 - val_accuracy: 0.8571\n",
            "Epoch 30/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.8541\n",
            "Epoch 30: val_accuracy did not improve from 0.97959\n",
            "24/24 [==============================] - 88s 4s/step - loss: 0.4751 - accuracy: 0.8541 - val_loss: 0.1813 - val_accuracy: 0.9592\n"
          ]
        }
      ],
      "source": [
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(\n",
        "       aug.flow(trainX, trainY, batch_size=BS),\n",
        "       validation_data=(testX, testY),\n",
        "       steps_per_epoch=len(trainX) // BS,\n",
        "       epochs=EPOCHS,\n",
        "       # class_weight=class_weight_dic, \n",
        "       callbacks=callbacks_list,\n",
        "       verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4b2b01",
      "metadata": {
        "id": "bf4b2b01"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "zhyKX3yeYwie",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhyKX3yeYwie",
        "outputId": "28da52bc-29ca-4841-9720-4050dd8ff126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] serializing network...\n",
            "INFO:tensorflow:Assets written to: results/weld_3cls.model/assets\n",
            "[INFO] serializing label binarizer...\n"
          ]
        }
      ],
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save('results/weld_3cls.model')\n",
        "\n",
        "# save the label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "f = open('results/lb.pickle', \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "XYrWORxfGtbC",
      "metadata": {
        "id": "XYrWORxfGtbC"
      },
      "outputs": [],
      "source": [
        "# Save training history\n",
        "# Convert history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(H.history)\n",
        "hist_csv_file = 'results/history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455bd251",
      "metadata": {
        "id": "455bd251"
      },
      "source": [
        "## Predict on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ukG6Zs86YXg_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukG6Zs86YXg_",
        "outputId": "884754f6-6c5c-46dc-98ae-15a0a205a750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n"
          ]
        }
      ],
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "dnv4_GjUW6yT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnv4_GjUW6yT",
        "outputId": "1ada0ac0-9563-493d-b0c0-54f18bb6fdde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 2, 2,\n",
              "       2, 2, 1, 2, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 0, 0, 1, 0,\n",
              "       2, 1, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Retrieve index of the label corresponding largest predicted probability for each image in testing set using argmax\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "predIdxs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e02e2ec",
      "metadata": {
        "id": "3e02e2ec"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "qk7l0yARdsX7",
      "metadata": {
        "id": "qk7l0yARdsX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570b144c-78a8-433b-857e-2f696a3fb102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 6s 2s/step - loss: 0.1813 - accuracy: 0.9592\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(testX, testY, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "sMbtbio_e_f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMbtbio_e_f5",
        "outputId": "1fe7478e-03bf-4318-8887-661b4d639ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss is found to be 0.18 and accuracy is found to be 95.92 percent !\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = score[0], score[1]\n",
        "print(\"The loss is found to be %.2f and accuracy is found to be %.2f percent !\" %(loss,accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d76ec89",
      "metadata": {
        "id": "6d76ec89"
      },
      "source": [
        "## Display classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "JOrcxXOWtGZW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOrcxXOWtGZW",
        "outputId": "1feed8a5-2fa0-49f2-e7fd-73bd5c8f27a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "cluster_porosity       0.91      0.91      0.91        11\n",
            "          cracks       1.00      1.00      1.00        17\n",
            "       no_defect       0.95      0.95      0.95        21\n",
            "\n",
            "        accuracy                           0.96        49\n",
            "       macro avg       0.95      0.95      0.95        49\n",
            "    weighted avg       0.96      0.96      0.96        49\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "welding_defect_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}